{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developer: Angel Chiu / @9ukei\n",
    "# Program Name: air_ticket_scraping.ipynb\n",
    "# Date: 2023/08/14\n",
    "# Function: 1. Scraping Air Ticket Prices\n",
    "#           2. Saving Air Ticket Price Data as CSV\n",
    "#           3. Uploading Air Ticket Price Data to Google Sheets\n",
    "#           4. Regular Notifications via Line Notify: Top 3 Airlines with Lowest Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. First, ensure that the `selenium`, `BeautifulSoup4`, and `lxml` libraries are installed on your device.\n",
    "2. If you have already installed these required packages for your project, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install selenium, BeautifulSoup4, lxml\n",
    "# !pip install selenium\n",
    "# !pip install BeautifulSoup4\n",
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/tf8z0v6j5cq6506t24xz7j5w0000gn/T/ipykernel_5278/3714825685.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/Users/hsin/chromedriver-mac-arm64/chromedriver')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('/usr/local/bin/chromedriver')\n",
    "\n",
    "# Crawl the URL that you wanted to scrape on Line travel\n",
    "# Here, I will take the example of comparing flight prices for flights from Taipei (TPE) to Osaka (OSA) for the dates 9/11 to 9/16.\n",
    "air_ticket_url = '''\n",
    "https://travel.line.me/flights/list?roundType=1&cabinClass=1&numOfAdult=2&numOfChildren=0&numOfBaby=0&linePointsRebateOnly=1&departureAirports=&departureCities=TPE&departureDates=1694390400000&arrivalAirports=&arrivalCities=OSA&departureAirports=&departureCities=OSA&departureDates=1694822400000&arrivalAirports=&arrivalCities=TPE\n",
    "'''\n",
    "\n",
    "# This number of seconds can be adjusted and increased according to the network delay problem. \n",
    "# It is recommended to stay at least 10 seconds or more.\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(air_ticket_url)\n",
    "\n",
    "# load more results to maximize the scraping\n",
    "def page_scrolldown():\n",
    "    try:\n",
    "        for i in range(1,20):\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "            time.sleep(0.7)\n",
    "    except:\n",
    "        print('Check to see if any code is causing the error.')\n",
    "        pass\n",
    "page_scrolldown()\n",
    "\n",
    "# view the html source code of the website\n",
    "driver.page_source\n",
    "\n",
    "html_source_code = driver.page_source\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to strip comma in Python string\n",
    "# https://stackoverflow.com/questions/16233593/how-to-strip-comma-in-python-string\n",
    "#a = total_price.replace(',', '')\n",
    "#print(int(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœå°‹çš„æ©Ÿç¥¨æ¯”åƒ¹ç¸½ç­†æ•¸ï¼š 687 å€‹èˆªç­\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_source_code, 'html.parser')\n",
    "\n",
    "# check source code without tags\n",
    "# print(soup.text)\n",
    "\n",
    "# Display the total number of tickets found\n",
    "record = soup.select_one('#__next > div.css-1cp3u8n.e1ugfpty0 > div:nth-child(2) > span')\n",
    "print('æœå°‹çš„æ©Ÿç¥¨æ¯”åƒ¹ç¸½ç­†æ•¸ï¼š',record.text)\n",
    "#\n",
    "\n",
    "time_loc_list = []\n",
    "\n",
    "for time_loc_info in soup.select('#__next > div.css-1cp3u8n.e1ugfpty0 > div:nth-child(2)'):\n",
    "    for tl in time_loc_info.select('.css-nkthol.ejxn77z1, .css-1qzlsgj.e1fe20ih2'):\n",
    "        time = tl.text\n",
    "        time_loc_list.append(time)\n",
    "\n",
    "# éæ­· time_loc_list ä¸­çš„å…ƒç´ ï¼Œæ¯æ¬¡å–å…«å€‹å…ƒç´ çµ„åˆæˆä¸€å€‹å…ƒçµ„ï¼Œä¸¦å°‡é€™äº›å…ƒçµ„æ”¾å…¥ tuple_list ä¸­\n",
    "tuple_list = [tuple(time_loc_list[i:i+8]) for i in range(0, len(time_loc_list), 8)]\n",
    "# print(tuple_list)\n",
    "\n",
    "df_time = pd.DataFrame(tuple_list, columns=[\"èµ·é£›æ™‚é–“(å‡ºç™¼)\",\"èµ·é£›åœ°é»(å‡ºç™¼)\",\"æŠµé”æ™‚é–“(å‡ºç™¼)\",\"æŠµé”åœ°é»(å‡ºç™¼)\", \"èµ·é£›æ™‚é–“(å›ç¨‹)\",\"èµ·é£›åœ°é»(å›ç¨‹)\", \"æŠµé”æ™‚é–“(å›ç¨‹)\",\"æŠµé”åœ°é»(å›ç¨‹)\"])\n",
    "\n",
    "result = []\n",
    "\n",
    "# Depart/Arrived time + location (aboard/arrived)\n",
    "for time_loc_info in soup.select('#__next > div.css-1cp3u8n.e1ugfpty0 > div:nth-child(2)'):\n",
    "    for tl in time_loc_info.select('.css-1eowobi .css-j7qwjs'):\n",
    "        time_loc = tl.text\n",
    "        # print(time_loc)\n",
    "\n",
    "air_ticket_info = soup.find_all(class_='css-1eowobi')\n",
    "\n",
    "for ticket_info in air_ticket_info:\n",
    "    # airline company\n",
    "    airline = ticket_info.find(class_='css-84a4s3 e1fe20ih3').getText().strip()\n",
    "    # air ticket provider\n",
    "    ticket_site = ticket_info.find(class_='css-6x2xcr e1fe20ih2').getText().strip()   \n",
    "    # ticket per price\n",
    "    ticket_per_price = ticket_info.find(class_='css-iw7h7v ejxn77z0').getText().strip().replace(',', '')\n",
    "    # total ticket price(2 ppl)\n",
    "    total_price = ticket_info.find(class_='css-wycfi3 e1fe20ih3').getText().strip('')[9:].replace(',', '')\n",
    "    # ticket purchase url\n",
    "    ticket_purchase_url = 'https://travel.line.me/' + ticket_info.find('a').get('href')\n",
    "\n",
    "    result.append((airline,ticket_site,int(ticket_per_price),int(total_price), ticket_purchase_url))\n",
    "\n",
    "    #print(airline,ticket_site, ticket_per_price, total_price)\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"èˆªç©ºå…¬å¸\", \"è³¼è²·ç¶²ç«™\", \"ä¸€äººåƒ¹æ ¼(TWD)\", \"å…©äººç¸½åƒ¹(TWD)\", \"è²·ç¥¨å»ï¼\"])\n",
    "\n",
    "#print(df.head(30))\n",
    "\n",
    "# print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   èµ·é£›æ™‚é–“(å‡ºç™¼) èµ·é£›åœ°é»(å‡ºç™¼) æŠµé”æ™‚é–“(å‡ºç™¼) æŠµé”åœ°é»(å‡ºç™¼) èµ·é£›æ™‚é–“(å›ç¨‹) èµ·é£›åœ°é»(å›ç¨‹) æŠµé”æ™‚é–“(å›ç¨‹) æŠµé”åœ°é»(å›ç¨‹)  \\\n",
      "1     21:55      TPE    01:30      ICN    02:30      ICN    04:05      TPE   \n",
      "2     21:55      TPE    01:30      ICN    07:50      ICN    09:25      TPE   \n",
      "3     18:00      TPE    21:35      ICN    02:30      ICN    04:05      TPE   \n",
      "4     13:50      TSA    17:25      GMP    07:50      ICN    09:25      TPE   \n",
      "5     13:50      TSA    17:25      GMP    02:30      ICN    04:05      TPE   \n",
      "6     18:00      TPE    21:35      ICN    07:50      ICN    09:25      TPE   \n",
      "7     21:55      TPE    01:30      ICN    09:05      ICN    10:50      TPE   \n",
      "8     10:35      TPE    14:00      ICN    07:50      ICN    09:25      TPE   \n",
      "9     13:50      TSA    17:25      GMP    09:05      ICN    10:50      TPE   \n",
      "10    21:55      TPE    01:30      ICN    12:55      ICN    17:40      TPE   \n",
      "\n",
      "           èˆªç©ºå…¬å¸       è³¼è²·ç¶²ç«™  ä¸€äººåƒ¹æ ¼(TWD)  å…©äººç¸½åƒ¹(TWD)  \\\n",
      "1          å°ç£è™èˆª  ezfly æ˜“é£›ç¶²       5468      10936   \n",
      "2      å°ç£è™èˆªã€çœŸèˆªç©º  BudgetAir       6953      13906   \n",
      "3       é…·èˆªã€å°ç£è™èˆª  ezfly æ˜“é£›ç¶²       7122      14244   \n",
      "4      å¾·å¨èˆªç©ºã€çœŸèˆªç©º   Trip.com       7345      14690   \n",
      "5     å¾·å¨èˆªç©ºã€å°ç£è™èˆª   Trip.com       7360      14720   \n",
      "6        é…·èˆªã€çœŸèˆªç©º   Trip.com       7586      15172   \n",
      "7     å°ç£è™èˆªã€æ¿Ÿå·èˆªç©º  ezfly æ˜“é£›ç¶²       7725      15450   \n",
      "8           çœŸèˆªç©º  BudgetAir       8169      16338   \n",
      "9     å¾·å¨èˆªç©ºã€æ¿Ÿå·èˆªç©º  BudgetAir       8235      16470   \n",
      "10  å°ç£è™èˆªã€ä¸­åœ‹æ±æ–¹èˆªç©º  BudgetAir       8275      16550   \n",
      "\n",
      "                                                 è²·ç¥¨å»ï¼  \n",
      "1   https://travel.line.me//flights/2b8164c503cee7...  \n",
      "2   https://travel.line.me//flights/38f866ac44ca06...  \n",
      "3   https://travel.line.me//flights/7344208ac10b58...  \n",
      "4   https://travel.line.me//flights/b7a53c5dd41a9f...  \n",
      "5   https://travel.line.me//flights/dbb6a0471f094e...  \n",
      "6   https://travel.line.me//flights/f0fdc2dece43ab...  \n",
      "7   https://travel.line.me//flights/8ce65389635cb8...  \n",
      "8   https://travel.line.me//flights/94e1c136bfb235...  \n",
      "9   https://travel.line.me//flights/e9bfb27f4acb05...  \n",
      "10  https://travel.line.me//flights/085dee8a76be30...  \n"
     ]
    }
   ],
   "source": [
    "# å¦‚æœ df1 å’Œ df2 çš„åˆ—æ•¸ç›¸åŒï¼Œä½†æ˜¯æ¬„ä½åç¨±ä¸åŒï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ concat å‡½æ•¸å°‡å®ƒå€‘åˆä½µåœ¨ä¸€èµ·ã€‚concat å‡½æ•¸å¯ä»¥åœ¨æŒ‡å®šçš„è»¸ä¸Šé€£æ¥å¤šå€‹ DataFrameã€‚\n",
    "# åœ¨æ‚¨çš„æƒ…æ³ä¸‹ï¼Œæ‚¨å¯ä»¥é¸æ“‡åœ¨åˆ—è»¸ä¸Šé€²è¡Œé€£æ¥ã€‚\n",
    "\n",
    "ticket_full_info = pd.concat([df_time, df], axis=1)\n",
    "ticket_full_info.align\n",
    "ticket_full_info.index +=1\n",
    "print(ticket_full_info.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "# è‹¥æœˆä»½éç‚º 10~12 æœˆï¼Œå‰‡åœ¨ 1~9 æœˆä»½å¾Œé¢åŠ ä¸€å€‹ 0\n",
    "if now.month <= 10:\n",
    "    date = str(now.year)+'0'+str(now.month)+str(now.day)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# ç¾åœ¨æ™‚é–“\n",
    "loc_dt = datetime.datetime.today() \n",
    "loc_dt_format = loc_dt.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "# dataframe to csv\n",
    "scapring_date = date\n",
    "ticket_full_info.to_csv(f\"{scapring_date}_air_ticket_full_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync data to Google Sheets by Pygsheets\n",
    "- To sync the air ticket data to `Google Sheets` in real time, we can use a Python module called `Pygsheets` to control Google Sheet API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pygsheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "\n",
    "auth_file = \"credentials/client_secret.json\"\n",
    "gc = pygsheets.authorize(service_file = auth_file)\n",
    "\n",
    "# sheet read by pygsheets\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1p5wOveW2B_bbbaBQdvpYdWcbFm_5XrRuec6Mhctqlx4/\" \n",
    "sheet = gc.open_by_url(sheet_url)\n",
    "\n",
    "#é¸å–byåç¨±\n",
    "air_ticket_sheet_01 = sheet.worksheet_by_title(\"air ticket price comparison\")\n",
    "\n",
    "# æ›´æ–°å·¥ä½œè¡¨ä¸­çš„å€¼\n",
    "# title_date = 'A1'\n",
    "# air_ticket_sheet_01.update_values(title_date, [['9/4 ~ 9/9 éŸ“åœ‹å°ç£ä¾†å›æ©Ÿç¥¨å³æ™‚æ¯”åƒ¹å ±è¡¨' + '\\n' + loc_dt_format]])\n",
    "attributes = 'A1'\n",
    "air_ticket_sheet_01.update_values(attributes, [[\"èµ·é£›æ™‚é–“(å‡ºç™¼)\",\"èµ·é£›åœ°é»(å‡ºç™¼)\",\"æŠµé”æ™‚é–“(å‡ºç™¼)\",\"æŠµé”åœ°é»(å‡ºç™¼)\", \"èµ·é£›æ™‚é–“(å›ç¨‹)\",\"èµ·é£›åœ°é»(å›ç¨‹)\", \"æŠµé”æ™‚é–“(å›ç¨‹)\",\"æŠµé”åœ°é»(å›ç¨‹)\",\"èˆªç©ºå…¬å¸\", \"è³¼è²·ç¶²ç«™\", \"ä¸€äººåƒ¹æ ¼(TWD)\", \"å…©äººç¸½åƒ¹(TWD)\", \"è²·ç¥¨å»ï¼\"]])\n",
    "start_record = 'A2'\n",
    "# `df.values.tolist()` method can transform the data type `dataframe` to `list`\n",
    "air_ticket_sheet_01.update_values(start_record, ticket_full_info.values.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Notify ä¸²æ¥ + Cron Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "def send_notification():\n",
    "\n",
    "    # Read the data from Google Sheets\n",
    "    data = air_ticket_sheet_01.get_all_records()\n",
    "\n",
    "    # Extract the top three combinations of airlines with the lowest prices\n",
    "    top_three_rows = data[:3]\n",
    "    \n",
    "    # Send LINE Notify notification   \n",
    "    line_notify_url = \"https://notify-api.line.me/api/notify\"\n",
    "\n",
    "    msg = '\\n9/4 ~ 9/9 å°ç£éŸ“åœ‹ä¾†å›æ©Ÿç¥¨\\nå³æ™‚æ¯”åƒ¹å ±è¡¨\\n\\n'\n",
    "    for row in top_three_rows:\n",
    "        msg += f'''ğŸ’èˆªç©ºå…¬å¸: {row[\"èˆªç©ºå…¬å¸\"]}\\nğŸ’ä¸€äººåƒ¹æ ¼(TWD): {row[\"ä¸€äººåƒ¹æ ¼(TWD)\"]}å…ƒ\\nğŸ’å…©äººç¸½åƒ¹(TWD): {row[\"å…©äººç¸½åƒ¹(TWD)\"]}å…ƒ\\nâœˆï¸å“ªæ¬¡ä¸è¡äº†ï¼Œè²·ç¥¨å»ï¼\\n{row[\"è²·ç¥¨å»ï¼\"]}\\n\\n'''\n",
    "    \n",
    "    # for test\n",
    "    # payload={'message':{msg}}\n",
    "    payload={'message':{msg}}\n",
    "    headers = {'Authorization': 'Bearer ' + '4APR0M6N9eQXzpCUC1SzuHLu7uAyMZN4cN4U71Q52ct'}\n",
    "    # Status code\n",
    "    response = requests.request(\"POST\", line_notify_url, headers=headers, data=payload)\n",
    "    print(response.text)\n",
    "\n",
    "# Set the time for sending notifications (Example: Every day at 10 AM)\n",
    "schedule.every().day.at(\"3:25\").do(send_notification)\n",
    "# schedule.every(60).seconds.do(send_notification)\n",
    "\n",
    "# Infinite loop to keep the script running\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
